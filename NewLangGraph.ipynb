{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6hH43MKyp/JMlRHoTfvS7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain-openai"
      ],
      "metadata": {
        "id": "pjnhFm6WX8nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "46f6d060-e262-40fa-a726-e3f92c57cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.14.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "sBXg94jcFWfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "h100rX9Ua5fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
      ],
      "metadata": {
        "id": "pHU5AeZpa1_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "Te4v30hxYlfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manager_node(state):\n",
        "    task_input = state.get(\"task\", \"\")\n",
        "    input = state.get(\"input\",\"\")\n",
        "    prompt = f\"\"\"\n",
        "    You are a task router. Based on the user request below, decide whether it is a:\n",
        "    - translate\n",
        "    - summarize\n",
        "    - calculate\n",
        "\n",
        "    Respond with only one word (translate, summarize, or calculate).\n",
        "\n",
        "    Task: {task_input}\n",
        "    \"\"\"\n",
        "    decision = llm.invoke(prompt).content.strip().lower()\n",
        "    return {\"agent\": decision, \"input\":input}"
      ],
      "metadata": {
        "id": "kHbLuaV2YyIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Worker Nodes\n",
        "def translator_node(state):\n",
        "    text = state.get(\"input\", \"\")\n",
        "    prompt = f\"Act like You are a translator. Only respond with the English translation of the text below:\\n\\n{text}\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"result\": result}\n",
        "\n",
        "def summarizer_node(state):\n",
        "    text = state.get(\"input\", \"\")\n",
        "    prompt = f\"Summarize the following in 1-2 lines:\\n\\n{text}\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"result\": result}\n",
        "\n",
        "def calculator_node(state):\n",
        "    expression = state.get(\"input\", \"\")\n",
        "    prompt = f\"Please calculate and return the result of:\\n{expression}\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"result\": result}"
      ],
      "metadata": {
        "id": "fMhdd_FoYthD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_by_agent(state):\n",
        "    return {\n",
        "        \"translate\": \"Translator\",\n",
        "        \"summarize\": \"Summarizer\",\n",
        "        \"calculate\": \"Calculator\",\n",
        "        \"input\": state.get(\"input\", \"\")\n",
        "    }.get(state.get(\"agent\", \"\"), \"Default\")\n"
      ],
      "metadata": {
        "id": "skZ-R_W4Y5kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhm79x8WX4JG"
      },
      "outputs": [],
      "source": [
        "def default_node(state):\n",
        "    return {\"result\": \"Sorry, I couldn't understand the task.\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "g = StateGraph(dict)\n",
        "g.add_node(\"Manager\", manager_node)\n",
        "g.add_node(\"Translator\", translator_node)\n",
        "g.add_node(\"Summarizer\", summarizer_node)\n",
        "g.add_node(\"Calculator\", calculator_node)\n",
        "g.add_node(\"Default\", default_node)\n",
        "g.set_entry_point(\"Manager\")\n",
        "g.add_conditional_edges(\"Manager\", route_by_agent)\n",
        "g.set_finish_point(\"Translator\")\n",
        "g.set_finish_point(\"Summarizer\")\n",
        "g.set_finish_point(\"Calculator\")\n",
        "g.set_finish_point(\"Default\")\n",
        "graph = g.compile()"
      ],
      "metadata": {
        "id": "-xEy1qQZY_bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate Example\n",
        "print(graph.invoke({\n",
        "    \"task\": \"Can you translate this?\",\n",
        "    \"input\": \"Bonjour le monde\"\n",
        "}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjjbOi6rZEt6",
        "outputId": "74d17a57-3b22-4458-94f7-370560c5fbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'result': 'Hello world'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize Example\n",
        "print(graph.invoke({\n",
        "    \"task\": \"Please summarize the following\",\n",
        "    \"input\": \"LangGraph helps you build flexible multi-agent workflows in Python...\"\n",
        "}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZakp1mZHVp",
        "outputId": "8da371ef-a1a7-4cfb-8d4b-b8df5089050e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'result': 'LangGraph enables the creation of adaptable multi-agent workflows in Python, streamlining complex task management and collaboration.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "respcal = graph.invoke({\n",
        "    \"task\": \"What is 12 * 8 + 5?\",\n",
        "    \"input\": \"12 * 8 + 5\"\n",
        "})"
      ],
      "metadata": {
        "id": "4lDPvRjGZIv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(respcal['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deVbzv87sUc0",
        "outputId": "cca764bb-4696-43b3-ef49-debc69dbed5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of the calculation \\(12 \\times 8 + 5\\) is:\n",
            "\n",
            "\\[\n",
            "12 \\times 8 = 96\n",
            "\\]\n",
            "\n",
            "Then, adding 5:\n",
            "\n",
            "\\[\n",
            "96 + 5 = 101\n",
            "\\]\n",
            "\n",
            "So, the final result is \\(101\\).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unknown Example\n",
        "print(graph.invoke({\n",
        "    \"task\": \"Can you dance?\",\n",
        "    \"input\": \"foo\"\n",
        "}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANJA66C1ZKA4",
        "outputId": "71b82c24-1440-4804-f64d-8e2b04bc5fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'result': 'It seems like there may have been an error or misunderstanding, as \"foo\" does not provide enough context or content to summarize. Please provide more information or clarify what you would like summarized!'}\n"
          ]
        }
      ]
    }
  ]
}