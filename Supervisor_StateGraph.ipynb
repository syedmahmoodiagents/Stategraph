{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFBro8CCPgdraDQ9vALDg+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/Stategraph/blob/main/Supervisor_StateGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-core langchain-community langchain-openai langgraph --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvWKcu7U2O8n",
        "outputId": "b7e26fe2-f736-4e55-fbae-3ad5f38245dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "sCliC0Cq2N-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph-supervisor --q"
      ],
      "metadata": {
        "id": "ZqKWdCKz3Wpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor"
      ],
      "metadata": {
        "id": "CzztaHUJ3E30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "gE77akrp2oiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN8q6fXy2qd2",
        "outputId": "81c1db21-320b-4e59-9e91-63bd0e24875a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS9ew2Lr2KEo"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "worker_math = create_react_agent(\n",
        "    llm,\n",
        "    tools=[],   # Math agent does reasoning only\n",
        "    name=\"math_worker\"\n",
        ")\n",
        "\n",
        "worker_writer = create_react_agent(\n",
        "    llm,\n",
        "    tools=[],\n",
        "    name=\"writer_worker\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3yHEQgN3zED",
        "outputId": "4b927ec5-2039-4a7c-b911-177de65d069e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1485497631.py:1: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  worker_math = create_react_agent(\n",
            "/tmp/ipython-input-1485497631.py:7: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  worker_writer = create_react_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supervisor_auto = create_supervisor(\n",
        "    model=llm,\n",
        "    agents=[worker_math, worker_writer],\n",
        "    system_message=(\n",
        "        \"You are a supervisor. \"\n",
        "        \"If the question is math -> send to math_worker. \"\n",
        "        \"If writing -> send to writer_worker.\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "_L8fN4O63859"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = supervisor_auto.compile()"
      ],
      "metadata": {
        "id": "6OxF9Mpy5hSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_auto = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Write a 2-sentence story about a robot.\")]\n",
        "})"
      ],
      "metadata": {
        "id": "yUamjYme2mtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_auto[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sDlMcB14HKO",
        "outputId": "5d0efc73-7338-43fc-badc-69c8e2d40176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a world where emotions were reserved for humans, a curious little robot named Chip accidentally discovered laughter while trying to understand a joke his creator told. From that day on, he embarked on a mission to bring joy to everyone he met, proving that even circuits could spark happiness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zbzq9FoC5vPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Manual StateGraph"
      ],
      "metadata": {
        "id": "RBMB-QBI6hID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, TypedDict\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "# from langgraph.constants import START"
      ],
      "metadata": {
        "id": "vZRqDyG_6ly6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: List"
      ],
      "metadata": {
        "id": "4GCFnkkr6kCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_math_node(state: AgentState):\n",
        "    response = llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": \"You are a math specialist.\"},\n",
        "        *state[\"messages\"]\n",
        "    ])\n",
        "    return {\"messages\": state[\"messages\"] + [response]}\n"
      ],
      "metadata": {
        "id": "unSAJkD-6u5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_writer_node(state: AgentState):\n",
        "    response = llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": \"You are a writing specialist.\"},\n",
        "        *state[\"messages\"]\n",
        "    ])\n",
        "    return {\"messages\": state[\"messages\"] + [response]}\n"
      ],
      "metadata": {
        "id": "FbS3Ynt760VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def supervisor_router(state: AgentState):\n",
        "\n",
        "    first_human_message_content = \"\"\n",
        "    for message in state[\"messages\"]:\n",
        "        if isinstance(message, HumanMessage):\n",
        "            first_human_message_content = message.content.lower()\n",
        "            break\n",
        "\n",
        "    if \"calculate\" in first_human_message_content or any(x in first_human_message_content for x in [\"add\", \"sum\", \"math\"]):\n",
        "        return \"worker_math\"\n",
        "    # Default to writer if no specific math keywords are found in the original human message\n",
        "    return \"worker_writer\""
      ],
      "metadata": {
        "id": "lChn0WM-62KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervisor_node(state: AgentState):\n",
        "    sup_msg = llm.invoke([\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are a supervisor. Decide which worker to call.\"},\n",
        "        *state[\"messages\"]\n",
        "    ])\n",
        "    return {\"messages\": state[\"messages\"] + [sup_msg]}\n"
      ],
      "metadata": {
        "id": "y3yoz5G57ltr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"supervisor\", supervisor_node)\n",
        "graph.add_node(\"worker_math\", worker_math_node)\n",
        "graph.add_node(\"worker_writer\", worker_writer_node)\n",
        "\n",
        "# Edges\n",
        "graph.add_edge(START, \"supervisor\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    supervisor_router,\n",
        "    {\n",
        "        \"worker_math\": \"worker_math\",\n",
        "        \"worker_writer\": \"worker_writer\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Workers now go directly to END after completing their task\n",
        "graph.add_edge(\"worker_math\", END)\n",
        "graph.add_edge(\"worker_writer\", END)\n",
        "\n",
        "# graph.add_edge(\"worker_math\", \"supervisor\")\n",
        "# graph.add_edge(\"worker_writer\", \"supervisor\")\n",
        "# graph.add_edge(\"supervisor\", END) # Supervisor's role is now to route to a worker, not provide a final answer directly.\n",
        "\n",
        "supervisor_manual = graph.compile()"
      ],
      "metadata": {
        "id": "3tBstAdi7sIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61f49761"
      },
      "source": [
        "result_manual = supervisor_manual.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Write a 2-sentence story about a robot.\")]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93e806ff",
        "outputId": "d2a815f8-8999-4fce-f8a2-b1eb561aface"
      },
      "source": [
        "print(result_manual[\"messages\"][-1].content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a future dominated by technology, a small robot named Pixel stumbled upon a forgotten park, overgrown with weeds and litter. Determined to restore its beauty, Pixel worked tirelessly, transforming the area into a vibrant sanctuary that rekindled the community’s connection with nature.\n"
          ]
        }
      ]
    }
  ]
}